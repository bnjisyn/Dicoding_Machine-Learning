# -*- coding: utf-8 -*-
"""Dicoding Submission_Model ML LSTM Time Series_Benjamin Nikholas

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MQcq0DhO_t91QIQJuHwrlBYf2Ui-Hi78

# Project Kedua: Membuat Model Machine Learning dengan Data Time Series (LSTM)
---
---
* Nama: Benjamin Nikholas
* Email: benjisturi@gmail.com
* Nomor Telp : [6287892677303](wa.me/6287892677303)

Kriteria Parameter:
1. Dataset yang akan dipakai bebas, namun minimal memiliki 1000 sampel.
2. Harus menggunakan LSTM dalam arsitektur model.
3. Validation set sebesar 20% dari total dataset.
4. Model harus menggunakan model sequential.
5. Harus menggunakan Learning Rate pada Optimizer.
6. MAE < 10% skala data.

---

Kriteria target nilai sempurna **(bintang 5)**:
1. dataset yang digunakan memiliki banyak sampel data (>10000)
2. Mengimplementasikan Callback
3. Membuat plot loss dan akurasi pada saat training dan validation

### Library and Packages
"""

import os
import zipfile
from google.colab import files
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.dates import MonthLocator, DateFormatter
plt.rcParams['figure.figsize'] = 15, 6
import seaborn as sns
import tensorflow as tf
from keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
import warnings
warnings.filterwarnings("ignore")
import random
from sklearn.utils import check_random_state
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Initialize random number generator to ensure reproducibility

def SetSeed(seed:int):
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    random.seed(seed)
    tf.random.set_seed(seed)
    check_random_state(seed)

"""### Data Download
---
Data yang digunakan merupakan data crypto BTC/USDT yang didownload dari [kaggle](https://www.kaggle.com/datasets/tencars/392-crypto-currency-pairs-at-minute-resolution)


Link lengkap ada dibawah ini:

`https://www.kaggle.com/datasets/tencars/392-crypto-currency-pairs-at-minute-resolution`

---
"""

# Install API Kaggle in Google Colaboratory
!pip install kaggle

# Upload API JSON File Credential

uploaded = files.upload()

# Move JSON File and giving access

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download ADA/USD Dataset

!kaggle datasets download -d prasoonkottarathil/btcinusd --file BTC-Hourly.csv
# !kaggle datasets download -d tencars/392-crypto-currency-pairs-at-minute-resolution --file adausd.csv

# Unzip zip file

with zipfile.ZipFile('/content/BTC-Hourly.csv.zip', 'r') as zip_ref:
    zip_ref.extractall('/content')

os.listdir('/content')

"""### Exploratory Data Analysis"""

df = pd.read_csv('/content/BTC-Hourly.csv')
df.info()

# Convert 'date' columns dtype to 'datetime'
df['date'] = pd.to_datetime(df['date'])

# Sorting date
df.sort_values('date', inplace = True)

# Data will be taken from early 2019 to late 2021

start_date = pd.to_datetime('2019-01-01 00:00:00')
# start_date = pd.to_datetime('2018-05-15 06:00:00')
end_date = pd.to_datetime('2022-01-01 00:00:00')
# end_date = pd.to_datetime('2022-03-01 00:00:00')

df = df[(df['date'] >= start_date) & (df['date'] < end_date)]

# Set 'date' column to be the index
df.set_index('date', inplace = True)

# Drop all columns except column 'open'
df = pd.DataFrame(df.iloc[:,2])

# Check data
df.head(5)

# Check new data info

df.info()

plt.plot(df)

# Menambahkan x-ticks per bulan
plt.gca().xaxis.set_major_locator(MonthLocator())
plt.gca().xaxis.set_major_formatter(DateFormatter('%b %Y'))
plt.xticks(rotation=50)
plt.title('BTC/USDT Crypto Data\n2019-2021')
plt.xlabel('Datetime', fontsize = 10)
plt.ylabel('Price', fontsize = 10)
plt.show()

# Normalize Dataset with MinMaxScaler

Scaler = MinMaxScaler(feature_range = (0, 1))
df_scaled = pd.DataFrame(Scaler.fit_transform(df))

# Sequencing Data

X, y = [], []
time_steps = 1
for i in range(len(df_scaled) - time_steps):
  X.append(df_scaled.iloc[i: (i + time_steps)].values)
  y.append(df_scaled.iloc[i + time_steps])

X, y = np.array(X), np.array(y)

# Split data to train (80%) and validation (20%)

X_train, X_val, y_train, y_val = train_test_split(X, y,
                                                  train_size = 0.8,
                                                  shuffle = False)

# Check X y train and validation data shape

print(X_train.shape)
print(y_train.shape)
print(X_val.shape)
print(y_val.shape)

# Initialize threshold mae (10% data)

threshold_mae = (df_scaled.max().values - df_scaled.min().values) * 0.1
print(f'threshold_mae 10% value: {threshold_mae}')

"""### LSTM Modeling"""

# LSTM Model

SetSeed(2024)

model = Sequential([

    # Add LSTM Layer
    layers.LSTM(128,
                return_sequences = True,
                input_shape=(None, 1)),
    layers.LSTM(64),

    # Add Fully Connected Layer
    layers.Dense(64,
                 activation = 'relu'),
    layers.Dropout(0.1),
    layers.Dense(32,
                 activation = 'relu'),
    layers.Dense(1,
                 activation = 'linear')
])

# Set up Optimizers

SetSeed(2024)

# Adam Optimizer
adam = optimizers.Adam(learning_rate = 0.001)
SGD = optimizers.SGD(learning_rate = 0.1,
                     momentum = 0.9)

# Implement Callbacks

EarlyStop = tf.keras.callbacks.EarlyStopping(
    monitor = 'mae',
    min_delta = 0.001,
    verbose = 1,
    patience = 5,
    restore_best_weights = True,
    mode = 'min'
)

# Model Compiling

model.compile(loss = tf.keras.losses.Huber(),
              optimizer = SGD,
              metrics = ['mae'])

# Fitting Model

model_fit = model.fit(X_train, y_train,
                      validation_data = (X_val, y_val),
                      epochs = 10,
                      verbose = 1,
                      callbacks = [EarlyStop],
                      batch_size = 128)

# Check model fitting history data

history = pd.DataFrame(model_fit.history)
history.info()

plt.plot(history.mae)

# Check threshold mae test

print(f'MAE Best value < Threshold Mae 10% : {history.mae.min() < threshold_mae}')

